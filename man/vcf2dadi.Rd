% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/vcf2dadi.R
\name{vcf2dadi}
\alias{vcf2dadi}
\title{Create a \code{dadi} SNP input file from a any vcf file.}
\usage{
vcf2dadi(data, fasta.ingroup = NULL, fasta.outgroup = NULL,
  sumstats.ingroup = NULL, sumstats.outgroup = NULL,
  dadi.input.filename = NULL, blacklist.id = NULL,
  blacklist.genotype = NULL, whitelist.markers = NULL,
  monomorphic.out = TRUE, snp.ld = NULL, common.markers = TRUE,
  maf.thresholds = NULL, maf.pop.num.threshold = 1, maf.approach = "SNP",
  maf.operator = "OR", max.marker = NULL, strata = NULL,
  pop.levels = NULL, pop.labels = NULL, pop.select = NULL,
  imputation.method = NULL, hierarchical.levels = "populations",
  num.tree = 50, pred.mean.matching = 0, random.seed = NULL,
  verbose = FALSE, parallel.core = parallel::detectCores() - 1)
}
\arguments{
\item{data}{11 options: VCF (SNPs or Haplotypes, 
to make the vcf population ready, see details below),
plink, stacks haplotype file, genind (library(adegenet)), 
genlight (library(adegenet)), gtypes (library(strataG)), genepop, 
and a data frame in long/tidy or wide format. 
\emph{See details} of \code{\link{tidy_genomic_data}}.}

\item{fasta.ingroup}{(optional) The fasta output file from STACKS. This file is 
required to use with an outgroup. Leave empty if no outgroup. 
Default: \code{fasta.ingroup = NULL}.}

\item{fasta.outgroup}{(optional) The fasta output file from STACKS. This file is 
required to use an outgroup. Default: \code{fasta.outgroup = NULL}.}

\item{sumstats.ingroup}{(optional) The sumstats output file from STACKS
when running STACKS for the ingroup fasta file.This file is 
required to use with an outgroup. Leave empty if no outgroup. 
Default: \code{sumstats.ingroup = NULL}.}

\item{sumstats.outgroup}{(optional) The sumstats output file from STACKS 
when running STACKS for the outgroup fasta file. This file is 
required to use an outgroup. Default: \code{sumstats.outgroup = NULL}.}

\item{dadi.input.filename}{(optional) Name of the \code{dadi} SNP input file 
written to the working directory. e.g. \code{dadi.file.tsv}. 
Default use date and time to make the file. If used, the file extension
need to finish with \code{.tsv or .txt}.}

\item{blacklist.id}{(optional) A blacklist with individual ID and
a column header 'INDIVIDUALS'. The blacklist is an object in your
global environment or a file in the working directory
(e.g. "blacklist.txt").
Default: \code{blacklist.id = NULL}.}

\item{blacklist.genotype}{(optional) Useful to erase genotype with below 
average quality, e.g. genotype with more than 2 alleles in diploid likely 
sequencing errors or genotypes with poor genotype likelihood or coverage. 
The blacklist has a minimum of 2 column headers (markers and individuals). 
Markers can be 1 column (CHROM or LOCUS or POS), 
a combination of 2 (e.g. CHROM and POS or CHROM and LOCUS or LOCUS and POS) or 
all 3 (CHROM, LOCUS, POS). The markers columns must be designated: CHROM (character
or integer) and/or LOCUS (integer) and/or POS (integer). The id column designated
INDIVIDUALS (character) columns header. The blacklist must be in the working 
directory (e.g. "blacklist.genotype.txt"). For de novo VCF, CHROM column 
with 'un' need to be changed to 1. 
Default: \code{blacklist.genotype = NULL} for no blacklist of 
genotypes to erase.}

\item{whitelist.markers}{(optional) A whitelist containing CHROM (character
or integer) and/or LOCUS (integer) and/or
POS (integer) columns header. To filter by chromosome and/or locus and/or by snp.
The whitelist is in the working directory (e.g. "whitelist.txt").
de novo CHROM column with 'un' need to be changed to 1. 
In the VCF, the column ID is the LOCUS identification.
Default \code{whitelist.markers = NULL} for no whitelist of markers.}

\item{monomorphic.out}{(optional) Should the monomorphic 
markers present in the dataset be filtered out ? 
Default: \code{monomorphic.out = TRUE}.}

\item{snp.ld}{(optional) \strong{For VCF file only}. 
SNP short distance linkage disequilibrium pruning. With anonymous markers from
RADseq/GBS de novo discovery, you can minimize linkage disequilibrium (LD) by
choosing among these 3 options: \code{"random"} selection, \code{"first"} or
\code{"last"} SNP on the same short read/haplotype. For long distance linkage
disequilibrium pruning, see details below.
Default: \code{snp.ld = NULL}.}

\item{common.markers}{(optional) Logical. Default: \code{common.markers = TRUE}, 
will only keep markers in common (genotyped) between all the populations.}

\item{maf.thresholds}{(string, double, optional) String with 
local/populations and global/overall maf thresholds, respectively.
e.g. \code{maf.thresholds = c(0.05, 0.1)} for a local maf threshold 
of 0.05 and a global threshold of 0.1. Available for VCF, PLINK and data frame 
files.
Default: \code{maf.thresholds = NULL}.}

\item{maf.pop.num.threshold}{(integer, optional) When maf thresholds are used,
this argument is for the number of pop required to pass the maf thresholds
to keep the locus. Default: \code{maf.pop.num.threshold = 1}}

\item{maf.approach}{(character, optional). 
\code{maf.approach = "haplotype"} : looks at the minimum MAF found on the 
read/haplotype. Using this option will discard all the markers/snp on 
that read based on the thresholds chosen. This method is only available 
for VCF and haplotype files, or tidy data frame from those file types.
\code{maf.approach = "SNP"} : treats all the SNP on the same 
haplotype/read as independent. Doesn't work with haplotype file, 
but does work for all other file type.
Default is \code{maf.approach = "SNP"}.}

\item{maf.operator}{(character, optional) \code{maf.operator = "AND"} or 
default \code{maf.operator = "OR"}.
When filtering over LOCUS or SNP, do you want the local \code{"AND"}
global MAF to pass the thresholds, or ... you want the local \code{"OR"}
global MAF to pass the thresholds, to keep the marker?}

\item{max.marker}{(integer, optional) For large PLINK files,
useful to subsample marker number. e.g. if the data set 
contains 200 000 markers and \code{max.marker = 10000}, 10000 markers are
subsampled randomly from the 200000 markers. If you need specific markers,
use \code{whitelist.markers} argument.
Default: \code{max.marker = NULL}.}

\item{strata}{(optional/required) Required for VCF and haplotypes files, 
optional for the other file formats supported. 

The strata file is a tab delimited file with 2 columns with header:
\code{INDIVIDUALS} and \code{STRATA}. With a 
data frame of genotypes the strata is the INDIVIDUALS and POP_ID columns, with
PLINK files, the \code{tfam} first 2 columns are used. 
If a \code{strata} file is specified, the strata file will have
precedence. The \code{STRATA} column can be any hierarchical grouping. 
To create a strata file see \code{\link[stackr]{individuals2strata}}.
If you have already run 
\href{http://catchenlab.life.illinois.edu/stacks/}{stacks} on your data, 
the strata file is similar to a stacks `population map file`, make sure you 
have the required column names (\code{INDIVIDUALS} and \code{STRATA}).
Default: \code{strata = NULL}.}

\item{pop.levels}{(optional, string) This refers to the levels in a factor. In this 
case, the id of the pop.
Use this argument to have the pop ordered your way instead of the default 
alphabetical or numerical order. e.g. \code{pop.levels = c("QUE", "ONT", "ALB")} 
instead of the default \code{pop.levels = c("ALB", "ONT", "QUE")}. 
White spaces in population names are replaced by underscore.
Default: \code{pop.levels = NULL}.}

\item{pop.labels}{(optional, string) Use this argument to rename/relabel
your pop or combine your pop. e.g. To combine \code{"QUE"} and \code{"ONT"} 
into a new pop called \code{"NEW"}:
(1) First, define the levels for your pop with \code{pop.levels} argument: 
\code{pop.levels = c("QUE", "ONT", "ALB")}. 
(2) then, use \code{pop.labels} argument: 
\code{pop.levels = c("NEW", "NEW", "ALB")}.
To rename \code{"QUE"} to \code{"TAS"}:
\code{pop.labels = c("TAS", "ONT", "ALB")}.
Default: \code{pop.labels = NULL}. If you find this too complicated, there is also the
\code{strata} argument that can do the same thing, see below.
White spaces in population names are replaced by underscore.}

\item{pop.select}{(string, optional) Selected list of populations for
the analysis. e.g. \code{pop.select = c("QUE", "ONT")} to select \code{QUE}
and \code{ONT} population samples (out of 20 pops).
Default: \code{pop.select = NULL}}

\item{imputation.method}{(character, optional) 
Methods available for map-independent imputations of missing genotype:

(1) \code{imputation.method = "max"} for Strawman imputation,
the most frequently observed genotypes (ties are broken at random) is used.

(2) \code{imputation.method = "rf"} On-the-fly-imputations using
Random Forests algorithm is used.

(3) \code{imputation.method = "boost"} extreme gradient boosting trees is used.

\code{imputation.method = NULL} will return the original dataset, without
imputation.
Default: \code{imputation.method = "rf"}.}

\item{hierarchical.levels}{(character, optional) \code{c("global", "populations")}.
Should the imputations be computed globally or by populations. Note that
imputing genotype globally in conjunction with \code{imputation.method = "max"}
can create huge bias for example by
introducing foreign genotypes in some populations (see note for more info).
Default: \code{hierarchical.levels = "populations"}.}

\item{num.tree}{(integer, optional) The number of trees to grow 
when \code{imputation.method = "rf"} or \code{imputation.method = "rf_pred"}.
Default: \code{num.tree = 50}.}

\item{pred.mean.matching}{(integer, optional) Used in conjunction with 
random Forests (\code{imputation.method = "rf_pred"}).
Number of candidate non-missing
value to sample from during the predictive mean matching step.
A fast k-nearest neighbor searching algorithms is used with this approach.
\code{pred.mean.matching = 3} will use 3 nighbors.
Default: \code{pred.mean.matching = 0}, avoids this step.}

\item{random.seed}{(integer, optional) For reproducibility, set an integer
that will be used to initialize the random generator. With default,
a random number is generated.
Default: \code{random.seed = NULL}.}

\item{verbose}{(optional, logical) When \code{verbose = TRUE} 
the function is a little more chatty during execution.
Default: \code{verbose = TRUE}.}

\item{parallel.core}{(optional) The number of core used for parallel
execution during vcf import.
Default: \code{parallel::detectCores() - 1}.}
}
\value{
The function returns a list with 1 or 2 objects (w/o imputations): 
`$dadi.no.imputation`
`$dadi.imputed`
The data frame are accessed form the list with `$`.
}
\description{
This function will create a \code{dadi} SNP input file using a
VCF file (Danecek et al. 2011). Missing data can bias demographic inference, 
\code{vcf2dadi} was created to address this problem, providing a customizable 
imputation framework specifically designed to work with GBS/RAD data.
If your VCF is not filtered, you can supply the function a whitelist of loci and a 
blacklist of individuals.
}
\details{
\strong{Input data:}
 
To discriminate the long from the wide format, 
the function \pkg{stackr} \code{\link[stackr]{tidy_wide}} searches 
for \code{MARKERS or LOCUS} in column names (TRUE = long format).
The data frame is tab delimitted.
\strong{Wide format:}
The wide format cannot store metadata info.
The wide format starts with these 2 id columns: 
\code{INDIVIDUALS}, \code{POP_ID} (that refers to any grouping of individuals), 
the remaining columns are the markers in separate columns storing genotypes.

\strong{Long/Tidy format:}
The long format is considered to be a tidy data frame and can store metadata info. 
(e.g. from a VCF see \pkg{stackr} \code{\link{tidy_genomic_data}}). A minimum of 4 columns
are required in the long format: \code{INDIVIDUALS}, \code{POP_ID}, 
\code{MARKERS or LOCUS} and \code{GENOTYPE or GT}. The rest are considered metata info.

\strong{2 genotypes formats are available:}
6 characters no separator: e.g. \code{001002 or 111333} (for heterozygote individual).
6 characters WITH separator: e.g. \code{001/002 or 111/333} (for heterozygote individual).
The separator can be any of these: \code{"/", ":", "_", "-", "."}.


\strong{Imputations details:}
The imputations using Random Forest requires more time to compute and can take several
minutes and hours depending on the size of the dataset and polymorphism of
the species used. e.g. with a low polymorphic taxa, and a data set 
containing 30\% missing data, 5 000 haplotypes loci and 500 individuals 
will require 15 min.
}
\examples{
#See vignette `vignette_vcf2dadi` for more info.
\dontrun{
dadi.no.imputation <- vcf2dadi(
data = "batch_1.vcf", 
whitelist.markers = "whitelist.loci.txt",
strata = "strata.file.tsv",
pop.levels = c("PAN", "COS"),
common.markers = TRUE, 
fasta.ingroup = "batch_1.ingroup.fa", 
fasta.outgroup = "batch_1.outgroup.fa", 
sumstats.ingroup = "batch_1.sumstats.ingroup.tsv", 
sumstats.outgroup = "batch_1.sumstats.outgroup.tsv"
)

With Imputations:
dadi.files <- vcf2dadi(
data = "batch_1.vcf", 
whitelist.markers = "whitelist.loci.txt",
strata = "strata.file.tsv",
pop.levels = c("PAN", "COS"),
common.markers = TRUE, 
fasta.ingroup = "batch_1.ingroup.fa", 
fasta.outgroup = "batch_1.outgroup.fa", 
sumstats.ingroup = "batch_1.sumstats.ingroup.tsv", 
sumstats.outgroup = "batch_1.sumstats.outgroup.tsv",
imputation.method = "max", 
hierarchical.levels = "populations", 
num.tree = 100, 
verbose = FALSE, 
parallel.core = 8
)
# to get the imputed data frame:
dadi.imputed.df <- dadi.files$dadi.imputed
}
}
\references{
Catchen JM, Amores A, Hohenlohe PA et al. (2011) 
Stacks: Building and Genotyping Loci De Novo From Short-Read Sequences. 
G3, 1, 171-182.

Catchen JM, Hohenlohe PA, Bassham S, Amores A, Cresko WA (2013) 
Stacks: an analysis tool set for population genomics. 
Molecular Ecology, 22, 3124-3140.

Danecek P, Auton A, Abecasis G et al. (2011)
The variant call format and VCFtools.
Bioinformatics, 27, 2156-2158.

Gutenkunst RN, Hernandez RD, Williamson SH, Bustamante CD (2009)
Inferring the Joint Demographic History of Multiple Populations 
from Multidimensional SNP Frequency Data (G McVean, Ed,). 
PLoS genetics, 5, e1000695.

Ishwaran H. and Kogalur U.B. (2015). Random Forests for Survival,
 Regression and Classification (RF-SRC), R package version 1.6.1.

Ishwaran H. and Kogalur U.B. (2007). Random survival forests
for R. R News 7(2), 25-31.

Ishwaran H., Kogalur U.B., Blackstone E.H. and Lauer M.S. (2008).
Random survival forests. Ann. Appl. Statist. 2(3), 841-860.
}
\author{
Thierry Gosselin \email{thierrygosselin@icloud.com} and
Anne-Laure Ferchaud \email{annelaureferchaud@gmail.com}
}
